# torchattn

PyTorch implementation of some attention networks.

**WIP**


&nbsp;

## Installation (optional)

```bash
git clone https://github.com/Renovamen/torchattn.git
cd torchattn
python setup.py install
```

or

```bash
pip install git+https://github.com/Renovamen/torchattn.git --upgrade
```


&nbsp;

## Implemented Networks

- Vanilla Attention

  [Neural Machine Translation by Jointly Learning to Align and Translate.](https://arxiv.org/abs/1409.0473) ICLR 2015.

  [Effective Approaches to Attention-based Neural Machine Translation.](https://arxiv.org/abs/1508.04025) EMNLP 2015.

- Multi-Head Self-Attention

  [Attention Is All You Need.](https://arxiv.org/abs/1706.03762) NIPS 2017.

- Simple Self-Attention

  [Self-Attention Generative Adversarial Networks.](https://arxiv.org/abs/1805.08318) ICML 2019.
